{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"},"colab":{"name":"generateFramesMasksFromVideo.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"code","metadata":{"id":"fP0uSXmXZqsM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"outputId":"6f62f8de-9a9b-4431-9bfc-504f0ad585a2","executionInfo":{"status":"ok","timestamp":1576746294882,"user_tz":-60,"elapsed":19864,"user":{"displayName":"Loris Pilotto","photoUrl":"","userId":"09223621215520058929"}}},"source":["#to access the data/files from the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IFQJIGovZqsZ","colab_type":"code","colab":{}},"source":["#PATHs: (don't forget the last '/')\n","##to load:\n","video3DName = '20190805_SJR3.2.2_w1_s2.nd2'\n","video3DPATH = '/content/drive/My Drive/gitRendu/data/videos/'\n","groundTruthPATH = '/content/drive/My Drive/gitRendu/data/annotations/'\n","idxNameMapPATH = '/content/drive/My Drive/gitRendu/data/annotations/'\n","##to save :\n","framesPATH = '/content/drive/My Drive/gitRendu/data/frames/'\n","masksPATH = '/content/drive/My Drive/gitRendu/data/masks/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G5C3wLufaTqo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"6cb32f97-ac2e-432d-dcad-88e10363da9e","executionInfo":{"status":"ok","timestamp":1576746658687,"user_tz":-60,"elapsed":3523,"user":{"displayName":"Loris Pilotto","photoUrl":"","userId":"09223621215520058929"}}},"source":["!pip install nd2reader"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: nd2reader in /usr/local/lib/python3.6/dist-packages (3.2.1)\n","Requirement already satisfied: pims>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from nd2reader) (0.4.1)\n","Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.6/dist-packages (from nd2reader) (1.17.4)\n","Requirement already satisfied: xmltodict>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from nd2reader) (0.12.0)\n","Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.6/dist-packages (from nd2reader) (1.12.0)\n","Requirement already satisfied: slicerator>=0.9.7 in /usr/local/lib/python3.6/dist-packages (from pims>=0.3.0->nd2reader) (1.0.0)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OcKcAwE1Zqsn","colab_type":"code","colab":{}},"source":["import numpy as np\n","import time\n","import glob, os\n","from nd2reader import ND2Reader\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from matplotlib import pyplot as plt\n","import skimage\n","import sys\n","from skimage.transform import resize\n","from scipy.ndimage import zoom\n","import cv2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7sCQqZfZqst","colab_type":"text"},"source":["# Functions"]},{"cell_type":"code","metadata":{"id":"HLc0_ZmfZqsz","colab_type":"code","colab":{}},"source":["def prep_nd2_reader(reader, c=1):\n","    \"\"\"\n","    Prepare the parameters of the ND2Reader object to be consistent with our data\n","    bundled_axes \"yxz\"\n","    default_cord for the channel of interest\n","    So looping over the reader goes stright through time\n","    \"\"\"\n","\n","    reader.default_coords['c'] = c\n","    reader.bundle_axes = 'yxz'\n","\n","\n","def get3DImage(images, time):\n","    #capture the nd2 3d image at a specific time\n","    #return shape : 312,512,35\n","    images.iter_axes = 't'\n","    image = images[time]\n","\n","    return image\n","\n","\n","def getMaskAsArray(maskDf, maskShape, time, nameMapDf):\n","    #return the mask at a specific time as an array\n","    #return shape : 312,512,35\n","    \n","    #select the good time\n","    maskDfTimed = maskDf[maskDf.Time == time]    \n","    #find 'Noise' value (to remove them from the mask)\n","    noiseValue = nameMapDf[nameMapDf.name == 'Noise'].values.tolist()[0][1]\n","    #remove 'Noise' from mask (i.e. 'Noise' will have value 0)\n","    #########we decided to keep the noise values\n","    maskDfTimedWithoutNoise = maskDfTimed#maskDfTimed[maskDfTimed.Segment != noiseValue]\n","    #create outpute array\n","    array = np.zeros(maskShape)\n","    #insert mask values in array\n","    maskList = maskDfTimedWithoutNoise[['x', 'y', 'z', 'Segment']].values.tolist()\n","    #print(maskList)\n","    for elt in maskList:\n","        array[elt[0], elt[1], elt[2]] = elt[3]\n","    return array\n","\n","def maskAllCells(mask, nameMap):\n","    #copy the mask\n","    result = mask.copy()\n","    #find the index of cells (except noise)\n","    nameMap = nameMap[nameMap.name != 'Noise']\n","    nameMap = nameMap[nameMap.name != 'noise']\n","    listIndex = nameMap[\" name_idx\"].tolist()\n","    #change the values of the mask\n","    result['Segment'] = result['Segment'].apply(lambda x: 1 if x in listIndex else 2)\n","    \n","    return result\n","\n","def AIANoduleGroundTruth(ground_truth_df, nameMap):\n","    #return a new ground_truth with the value 1 for 'AIA_terminal_nodule', 2 for 'AIA_central_nodule' and 3 for \n","    #all other cells parts. Also return a new 'idx_name_map' df\n","    \n","    #copy the dataframes\n","    resultGroundTruth = ground_truth_df.copy()\n","    resultNameMap = nameMap.copy()\n","    #give the groud_truth a new index called 'newName_idx' with value 3 by default\n","    resultNameMap['newName_idx'] = 3\n","    resultNameMap.loc[resultNameMap.name == 'AIA_terminal_nodule', 'newName_idx'] = 1\n","    resultNameMap.loc[resultNameMap.name == 'AIA_central_nodule', 'newName_idx'] = 2\n","    #create a dictionary to map from old index to new index on the mask\n","    dictionary = dict(zip(resultNameMap[' name_idx'], resultNameMap['newName_idx']))\n","    #map ground_truth Segment value from old to new index\n","    resultGroundTruth['Segment'] = resultGroundTruth['Segment'].map(dictionary)\n","    #create the corresponding 'idx_name_map' df\n","    resultNameMap.loc[resultNameMap.newName_idx == 3, 'name'] = 'Noise'\n","    resultNameMap = resultNameMap[['name', 'newName_idx']].drop_duplicates().rename(columns={'newName_idx': ' name_idx'})\\\n","                                                                                   .sort_values(by=[' name_idx']).reset_index(drop=True)\n","    return resultGroundTruth, resultNameMap"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ya3TSqKfZqs5","colab_type":"text"},"source":["# Generating the Frames & Masks "]},{"cell_type":"code","metadata":{"id":"wP6-repeZqs7","colab_type":"code","colab":{},"outputId":"d5f1dde8-bbfe-49c9-8bc3-22ccbc53da98"},"source":["gt_df = pd.read_csv(groundTruthPATH + video3DName[:-4] + '_ground_truth.csv')\n","nameMap_df = pd.read_csv(idxNameMapPATH + video3DName[:-4] + '_idx_name_map.csv')\n","realnd2FileName = video3DPATH + video3DName\n","\n","###shape of frame & mask\n","f_shape = (80, 128, 35)\n","m_shape = (80, 128, 35)\n","\n","print(video3DName[:-4] + '_ground_truth.csv')\n","print(video3DName[:-4] + '_idx_name_map.csv')\n","print(video3DName)\n","\n","with ND2Reader(realnd2FileName) as images:\n","\n","    images.iter_axes = 't'\n","    prep_nd2_reader(images)\n","    i = 0\n","    for image in images:\n","        \n","        print(\"Loading frame \",i)\n","        fp = \"frame_\"+str(int(i))+\".npy\"\n","        mp = \"mask_\"+str(int(i))+\".npy\"\n","        \n","        #the DenseNetFCN-3D need a precise input shape\n","        data_res = resize(image, f_shape)        \n","        np.save(framesPATH + fp, data_res[:,:,:32])\n","        \n","        resultGroundTruth, resultNameMap =  AIANoduleGroundTruth(gt_df, nameMap_df)\n","        mask = getMaskAsArray(resultGroundTruth, image.shape, i, resultNameMap)\n","        mask_res = resize(mask, m_shape, mode='edge',anti_aliasing=False,anti_aliasing_sigma=None, order=0)\n","\n","        np.save(masksPATH + mp, mask_res[:,:,:32])\n","\n","        i = i + 1\n","print(\"######################\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["20190805_SJR3.2.2_w1_s2_ground_truth.csv\n","20190805_SJR3.2.2_w1_s2_idx_name_map.csv\n","20190805_SJR3.2.2_w1_s2.nd2\n","Loading frame  0\n","Loading frame  1\n","Loading frame  2\n","Loading frame  3\n","Loading frame  4\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32m<ipython-input-29-e40842924807>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"mask_\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".npy\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mdata_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframesPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_res\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py\u001b[0m in \u001b[0;36mresize\u001b[1;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         image = ndi.gaussian_filter(image, anti_aliasing_sigma,\n\u001b[1;32m--> 149\u001b[1;33m                                     cval=cval, mode=ndi_mode)\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;31m# 2-dimensional interpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter\u001b[1;34m(input, sigma, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             gaussian_filter1d(input, sigma, axis, order, output,\n\u001b[1;32m--> 299\u001b[1;33m                               mode, cval, truncate)\n\u001b[0m\u001b[0;32m    300\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mgaussian_filter1d\u001b[1;34m(input, sigma, axis, order, output, mode, cval, truncate)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;31m# Since we are calling correlate, not convolve, revert the kernel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m     \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_gaussian_kernel1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcorrelate1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\ndimage\\filters.py\u001b[0m in \u001b[0;36mcorrelate1d\u001b[1;34m(input, weights, axis, output, mode, cval, origin)\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     _nd_image.correlate1d(input, weights, axis, output, mode, cval,\n\u001b[1;32m---> 95\u001b[1;33m                           origin)\n\u001b[0m\u001b[0;32m     96\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"6XxIit3CZqtG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AhNqG9nSZqtL","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}